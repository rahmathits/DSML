{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hello everyone!! the link contains notes from dav-2, dav-3, even advanced python (your next module) use what you need :)\n",
    "\n",
    "https://drive.google.com/drive/folders/1fKLTOzV0V8kLy04u8fmXu3NgIyP5Ecaj?usp=sharing\n",
    "\n",
    "my no is 9790723608, ping me if you have any doubts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice questions for Numpy/Pandas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# **1. Advanced Employee Performance Analysis**\n",
    "\n",
    "**Sample DataFrame**:\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "employee_data = pd.DataFrame({\n",
    "    'Employee_ID': ['E001', 'E002', 'E003', 'E004', 'E005'],\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Emma'],\n",
    "    'Department': ['HR', 'Finance', 'Engineering', 'Finance', 'HR'],\n",
    "    'Monthly_Sales': [8000, 12000, 15000, 14000, 9000],\n",
    "    'Client_Interactions': [20, 15, 30, 25, 18],\n",
    "    'Projects_Completed': [3, 4, 2, 5, 3]\n",
    "})\n",
    "```\n",
    "\n",
    "**Given Query**: \n",
    "\"First, calculate the sales per client interaction for each employee. Then, identify the employee with the highest sales per client interaction within each department. Finally, create a new DataFrame showing each departmentâ€™s total projects completed and total sales.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sales per client interaction for each employee:\n",
      "      Name  Sales_per_Interaction\n",
      "0    Alice                  400.0\n",
      "1      Bob                  800.0\n",
      "2  Charlie                  500.0\n",
      "3    David                  560.0\n",
      "4     Emma                  500.0\n",
      "\n",
      "Employee with the highest sales per client interaction within each department:\n",
      "    Department     Name  Sales_per_Interaction\n",
      "2  Engineering  Charlie                  500.0\n",
      "1      Finance      Bob                  800.0\n",
      "4           HR     Emma                  500.0\n",
      "\n",
      "Department-wise total projects completed and total sales:\n",
      "    Department  Projects_Completed  Monthly_Sales\n",
      "0  Engineering                   2          15000\n",
      "1      Finance                   9          26000\n",
      "2           HR                   6          17000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "employee_data = pd.DataFrame({\n",
    "    'Employee_ID': ['E001', 'E002', 'E003', 'E004', 'E005'],\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Emma'],\n",
    "    'Department': ['HR', 'Finance', 'Engineering', 'Finance', 'HR'],\n",
    "    'Monthly_Sales': [8000, 12000, 15000, 14000, 9000],\n",
    "    'Client_Interactions': [20, 15, 30, 25, 18],\n",
    "    'Projects_Completed': [3, 4, 2, 5, 3]\n",
    "})\n",
    "\n",
    "\n",
    "# Calculate sales per client interaction\n",
    "employee_data['Sales_per_Interaction'] = employee_data['Monthly_Sales'] / employee_data['Client_Interactions']\n",
    "\n",
    "# Identify the employee with the highest sales per client interaction within each department\n",
    "idx = employee_data.groupby('Department')['Sales_per_Interaction'].idxmax()\n",
    "top_performers = employee_data.loc[idx][['Department', 'Name', 'Sales_per_Interaction']]\n",
    "\n",
    "# Creating a new DataFrame for department-wise total projects and total sales\n",
    "department_summary = employee_data.groupby('Department')[['Projects_Completed', 'Monthly_Sales']].sum().reset_index()\n",
    "\n",
    "print(\"Sales per client interaction for each employee:\")\n",
    "print(employee_data[['Name', 'Sales_per_Interaction']])\n",
    "print(\"\\nEmployee with the highest sales per client interaction within each department:\")\n",
    "print(top_performers)\n",
    "print(\"\\nDepartment-wise total projects completed and total sales:\")\n",
    "print(department_summary)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2. Multi-Dimensional Sales Analysis**\n",
    "\n",
    "**Sample DataFrame**:\n",
    "```python\n",
    "sales_data = pd.DataFrame({\n",
    "    'Date': pd.to_datetime(['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05']),\n",
    "    'Product': ['A', 'B', 'A', 'A', 'B'],\n",
    "    'Region': ['North', 'South', 'East', 'West', 'East'],\n",
    "    'Units_Sold': [100, 200, 150, 180, 220],\n",
    "    'Revenue': [1000, 2500, 1200, 1800, 2700]\n",
    "})\n",
    "```\n",
    "\n",
    "**Given Query**: \n",
    "\"First, calculate the total revenue and total units sold for each product in each region. Next, identify the region with the highest total revenue. Finally, determine the day with the highest revenue to units sold ratio.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total revenue and total units sold for each product in each region:\n",
      "  Product Region  Units_Sold  Revenue\n",
      "0       A   East         150     1200\n",
      "1       A  North         100     1000\n",
      "2       A   West         180     1800\n",
      "3       B   East         220     2700\n",
      "4       B  South         200     2500\n",
      "\n",
      "Region with the highest total revenue: East\n",
      "\n",
      "Day with the highest revenue to units sold ratio: 2023-01-02 00:00:00\n"
     ]
    }
   ],
   "source": [
    "sales_data = pd.DataFrame({\n",
    "    'Date': pd.to_datetime(['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05']),\n",
    "    'Product': ['A', 'B', 'A', 'A', 'B'],\n",
    "    'Region': ['North', 'South', 'East', 'West', 'East'],\n",
    "    'Units_Sold': [100, 200, 150, 180, 220],\n",
    "    'Revenue': [1000, 2500, 1200, 1800, 2700]\n",
    "})\n",
    "\n",
    "# Calculate total revenue and total units sold for each product in each region\n",
    "product_region_summary = sales_data.groupby(['Product', 'Region'])[['Units_Sold', 'Revenue']].sum().reset_index()\n",
    "\n",
    "# Identify the region with the highest total revenue\n",
    "region_total_revenue = sales_data.groupby('Region')['Revenue'].sum()\n",
    "top_revenue_region = region_total_revenue.idxmax()\n",
    "\n",
    "# Determine the day with the highest revenue to units sold ratio\n",
    "sales_data['Revenue_per_Unit'] = sales_data['Revenue'] / sales_data['Units_Sold']\n",
    "highest_ratio_day = sales_data.loc[sales_data['Revenue_per_Unit'].idxmax()]['Date']\n",
    "\n",
    "print(\"Total revenue and total units sold for each product in each region:\")\n",
    "print(product_region_summary)\n",
    "print(f\"\\nRegion with the highest total revenue: {top_revenue_region}\")\n",
    "print(f\"\\nDay with the highest revenue to units sold ratio: {highest_ratio_day}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL query"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL Scenario-Based Question\n",
    "\n",
    "**Scenario 1:**\n",
    "You work for a company that manages a network of fitness centers. The database for these fitness centers contains the following tables:\n",
    "\n",
    "1. **Members**\n",
    "   - `member_id` (Primary Key)\n",
    "   - `name`\n",
    "   - `join_date`\n",
    "   - `membership_type` (e.g., Standard, Premium, Platinum)\n",
    "\n",
    "2. **Visits**\n",
    "   - `visit_id` (Primary Key)\n",
    "   - `member_id`\n",
    "   - `center_id`\n",
    "   - `visit_date`\n",
    "   - `duration_minutes`\n",
    "\n",
    "3. **Fitness_Centers**\n",
    "   - `center_id` (Primary Key)\n",
    "   - `center_name`\n",
    "   - `location`\n",
    "\n",
    "**Question:**\n",
    "Write a SQL query to find the average visit duration for each membership type for the current year (2023). Exclude any fitness centers that have had fewer than 100 visits in total for this period. The query should return the membership type and the average duration.\n",
    "\n",
    "\n",
    "\n",
    "**Scenario 2:**\n",
    "You are a data analyst at an e-commerce company. The database for the e-commerce platform contains the following tables:\n",
    "\n",
    "1. **Customers**\n",
    "   - `customer_id` (Primary Key)\n",
    "   - `name`\n",
    "   - `email`\n",
    "   - `join_date`\n",
    "   - `country`\n",
    "\n",
    "2. **Orders**\n",
    "   - `order_id` (Primary Key)\n",
    "   - `customer_id`\n",
    "   - `order_date`\n",
    "   - `amount`\n",
    "   - `status` (e.g., Completed, Pending, Cancelled)\n",
    "\n",
    "3. **Products**\n",
    "   - `product_id` (Primary Key)\n",
    "   - `name`\n",
    "   - `category`\n",
    "   - `price`\n",
    "\n",
    "4. **Order_Details**\n",
    "   - `detail_id` (Primary Key)\n",
    "   - `order_id`\n",
    "   - `product_id`\n",
    "   - `quantity`\n",
    "\n",
    "**Question:**\n",
    "Write a SQL query to identify the most popular product category in each country based on the total number of products sold, considering only completed orders for the year 2023. The query should return the country, the most popular product category, and the total quantity of products sold in that category.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Answer 1:\n",
    "\n",
    "```sql\n",
    "SELECT \n",
    "    M.membership_type,\n",
    "    AVG(V.duration_minutes) AS average_duration\n",
    "FROM \n",
    "    Visits V\n",
    "JOIN \n",
    "    Members M ON V.member_id = M.member_id\n",
    "JOIN \n",
    "    (SELECT \n",
    "        center_id \n",
    "     FROM \n",
    "        Visits \n",
    "     WHERE \n",
    "        YEAR(visit_date) = 2023 \n",
    "     GROUP BY \n",
    "        center_id \n",
    "     HAVING \n",
    "        COUNT(visit_id) >= 100\n",
    "    ) AS C ON V.center_id = C.center_id\n",
    "WHERE \n",
    "    YEAR(V.visit_date) = 2023\n",
    "GROUP BY \n",
    "    M.membership_type;\n",
    "```\n",
    "\n",
    "### Explanation:\n",
    "\n",
    "1. **Joining Tables:** The query joins the `Visits` table with the `Members` table to link member details to their visits.\n",
    "\n",
    "2. **Subquery for Filtering Fitness Centers:** A subquery is used to filter out fitness centers with fewer than 100 visits in 2023. This subquery selects `center_id` from `Visits` where the `visit_date` is in 2023 and groups by `center_id` with a `HAVING` clause to enforce the visit count condition.\n",
    "\n",
    "3. **Filtering Visits by Year:** The main query filters visits in the `Visits` table to include only those from the year 2023.\n",
    "\n",
    "4. **Aggregation:** The query calculates the average duration of visits (`AVG(V.duration_minutes)`) grouped by membership type (`M.membership_type`).\n",
    "\n",
    "This query provides the average visit duration for each membership type, considering only the fitness centers with sufficient visit frequency in the current year."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Answer 2:\n",
    "\n",
    "```sql\n",
    "SELECT \n",
    "    C.country,\n",
    "    P.category,\n",
    "    SUM(OD.quantity) AS total_quantity_sold\n",
    "FROM \n",
    "    Orders O\n",
    "JOIN \n",
    "    Customers C ON O.customer_id = C.customer_id\n",
    "JOIN \n",
    "    Order_Details OD ON O.order_id = OD.order_id\n",
    "JOIN \n",
    "    Products P ON OD.product_id = P.product_id\n",
    "WHERE \n",
    "    O.status = 'Completed' AND\n",
    "    YEAR(O.order_date) = 2023\n",
    "GROUP BY \n",
    "    C.country, P.category\n",
    "ORDER BY \n",
    "    C.country, total_quantity_sold DESC;\n",
    "```\n",
    "\n",
    "### Explanation:\n",
    "\n",
    "1. **Joining Tables:** The query joins `Orders`, `Customers`, `Order_Details`, and `Products` to relate customer details, order details, and product details.\n",
    "\n",
    "2. **Filtering Criteria:** It filters orders to include only those that are completed (`O.status = 'Completed'`) and placed in the year 2023 (`YEAR(O.order_date) = 2023`).\n",
    "\n",
    "3. **Aggregation and Grouping:** The query groups the results by `country` and `category`, and calculates the total quantity of products sold in each category (`SUM(OD.quantity)`).\n",
    "\n",
    "4. **Ordering Results:** Results are ordered by country and then by the total quantity sold in descending order, to identify the most popular category in each country.\n",
    "\n",
    "This query provides insights into the most popular product categories in each country based on the total sales volume for the year 2023, considering only completed orders."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Segmentation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link to Dataset\n",
    "\n",
    "[Sales Dataset](https://drive.google.com/file/d/1txmInRNwgPH6itjJORWg4CC0Rbna8wMc/view?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "-- Getting data at invoice level\n",
    "\n",
    "select InvoiceNo, (Quantity * UnitPrice) as amount\n",
    "\n",
    "from `mark_1.table-1` limit 10\n",
    "\n",
    "\n",
    "-- creating CTE for amount\n",
    "\n",
    "with bills as \n",
    "(\n",
    "  select InvoiceNo, (Quantity * UnitPrice) as amount from `mark_1.table-1`\n",
    ")\n",
    "\n",
    "select InvoiceNo, sum(amount) as total from bills group by InvoiceNo\n",
    "\n",
    "\n",
    "-- creating money value at customer level\n",
    "\n",
    "\n",
    "select s.CustomerID, sum(b.total) as monetary\n",
    "\n",
    "\n",
    "from `mark_1.table-1` s \n",
    "left join \n",
    "`mark_1.bill` b \n",
    "\n",
    "on s.InvoiceNo = b.InvoiceNo\n",
    "\n",
    "group by \n",
    "\n",
    "CustomerID\n",
    "\n",
    "-- add logic for recency\n",
    "\n",
    "with cte as \n",
    "\n",
    "(select s.CustomerID, sum(b.total) as monetary, DATE(max(s.InvoiceDate)) as last_purchase_date\n",
    "\n",
    "\n",
    "from `mark_1.table-1` s \n",
    "left join \n",
    "`mark_1.bill` b \n",
    "\n",
    "on s.InvoiceNo = b.InvoiceNo\n",
    "\n",
    "group by \n",
    "\n",
    "CustomerID)\n",
    "\n",
    "select *, DATE_DIFF(reference_date, last_purchase_date, DAY) as recency\n",
    "\n",
    "from \n",
    "\n",
    "( select *,\n",
    "\n",
    "MAX(last_purchase_date) OVER() + 1 as reference_date, \n",
    "\n",
    "from cte);\n",
    "\n",
    "-- add logic for frequency\n",
    "\n",
    "\n",
    "with cte as \n",
    "\n",
    "(select s.CustomerID, sum(b.total) as monetary, DATE(max(s.InvoiceDate)) as last_purchase_date, DATE(min(s.InvoiceDate)) as first_purchase_date, \n",
    "count(distinct s.InvoiceNo) as num_purchases,\n",
    "\n",
    "\n",
    "from `mark_1.table-1` s \n",
    "left join \n",
    "`mark_1.bill` b \n",
    "\n",
    "on s.InvoiceNo = b.InvoiceNo\n",
    "\n",
    "group by \n",
    "\n",
    "CustomerID)\n",
    "\n",
    "select *, DATE_DIFF(reference_date, last_purchase_date, DAY) as recency\n",
    "num_purchases / (months_cust) as frequency\n",
    "\n",
    "from \n",
    "\n",
    "( select *,\n",
    "\n",
    "MAX(last_purchase_date) OVER() + 1 as reference_date, \n",
    "DATE_DIFF(cte.last_purchase_date, cte.first_purchase_date, month) + 1 as months_cust\n",
    "\n",
    "from cte);\n",
    "\n",
    "\n",
    "-- let's create percentile\n",
    "\n",
    "\n",
    "SELECT\n",
    "   a.*,\n",
    "   --All percentiles for MONETARY\n",
    "   b.percentiles[offset(20)] AS m20,\n",
    "   b.percentiles[offset(40)] AS m40,\n",
    "   b.percentiles[offset(60)] AS m60,\n",
    "   b.percentiles[offset(80)] AS m80,\n",
    "   b.percentiles[offset(100)] AS m100,   \n",
    "   --All percentiles for FREQUENCY\n",
    "   c.percentiles[offset(20)] AS f20,\n",
    "   c.percentiles[offset(40)] AS f40,\n",
    "   c.percentiles[offset(60)] AS f60,\n",
    "   c.percentiles[offset(80)] AS f80,\n",
    "   c.percentiles[offset(100)] AS f100,   \n",
    "   --All percentiles for RECENCY\n",
    "   d.percentiles[offset(20)] AS r20,\n",
    "   d.percentiles[offset(40)] AS r40,\n",
    "   d.percentiles[offset(60)] AS r60,\n",
    "   d.percentiles[offset(80)] AS r80,\n",
    "   d.percentiles[offset(100)] AS r100\n",
    "FROM\n",
    "   `mark_1.RFM` a,\n",
    "   (SELECT APPROX_QUANTILES(monetary, 100) percentiles \n",
    "    FROM `mark_1.RFM`) b,\n",
    "   (SELECT APPROX_QUANTILES(frequency, 100) percentiles \n",
    "    FROM `mark_1.RFM`) c,\n",
    "   (SELECT APPROX_QUANTILES(recency, 100) percentiles \n",
    "    FROM `mark_1.RFM`) d\n",
    "ORDER BY CustomerID\n",
    "\n",
    "\n",
    "-- create scores\n",
    "\n",
    "select *,\n",
    "case when monetary <= m20 then 1\n",
    "    when monetary <= m40 and monetary >m20 then 2\n",
    "    when monetary <= m60 and monetary >m40 then 3\n",
    "    when monetary <= m80 and monetary >m60 then 4\n",
    "    when monetary <= m100 and monetary >m80 then 5\n",
    "    end as m_score,\n",
    "\n",
    "case when frequency <= f20 then 1\n",
    "    when frequency <= f40 and frequency >f20 then 2\n",
    "    when frequency <= f60 and frequency >f40 then 3\n",
    "    when frequency <= f80 and frequency >f60 then 4\n",
    "    when frequency <= f100 and frequency >f80 then 5\n",
    "    end as f_score,\n",
    "\n",
    "case when recency <= r20 then 5\n",
    "    when recency <= r40 and recency >r20 then 4\n",
    "    when recency <= r60 and recency >r40 then 3\n",
    "    when recency <= r80 and recency >r60 then 2\n",
    "    when recency <= r100 and recency >r80 then 1\n",
    "    end as r_score\n",
    "from mark_1.quintiles\n",
    "\n",
    "-- create segments\n",
    "\n",
    "SELECT \n",
    "  CustomerID,\n",
    "  m_score, f_score, r_score,\n",
    "  recency, frequency, monetary,\n",
    "  CAST(ROUND((f_score + m_score) / 2, 0) AS INT64) AS fm_score\n",
    "FROM (\n",
    "  \n",
    "select *,\n",
    "case when monetary <= m20 then 1\n",
    "    when monetary <= m40 and monetary >m20 then 2\n",
    "    when monetary <= m60 and monetary >m40 then 3\n",
    "    when monetary <= m80 and monetary >m60 then 4\n",
    "    when monetary <= m100 and monetary >m80 then 5\n",
    "    end as m_score,\n",
    "\n",
    "case when frequency <= f20 then 1\n",
    "    when frequency <= f40 and frequency >f20 then 2\n",
    "    when frequency <= f60 and frequency >f40 then 3\n",
    "    when frequency <= f80 and frequency >f60 then 4\n",
    "    when frequency <= f100 and frequency >f80 then 5\n",
    "    end as f_score,\n",
    "\n",
    "case when recency <= r20 then 5\n",
    "    when recency <= r40 and recency >r20 then 4\n",
    "    when recency <= r60 and recency >r40 then 3\n",
    "    when recency <= r80 and recency >r60 then 2\n",
    "    when recency <= r100 and recency >r80 then 1\n",
    "    end as r_score\n",
    "from mark_1.quintiles\n",
    ")\n",
    "\n",
    "-- create segments\n",
    "\n",
    "SELECT\n",
    "    CustomerID,\n",
    "    recency, frequency, monetary,\n",
    "    r_score, f_score, m_score,\n",
    "    fm_score,\n",
    "    CASE \n",
    "        WHEN (r_score = 5 AND fm_score = 5)\n",
    "          OR (r_score = 5 AND fm_score = 4)\n",
    "          OR (r_score = 4 AND fm_score = 5)\n",
    "        THEN 'Champions'\n",
    "        WHEN (r_score = 5 AND fm_score =3)\n",
    "          OR (r_score = 4 AND fm_score = 4)\n",
    "          OR (r_score = 3 AND fm_score = 5)\n",
    "          OR (r_score = 3 AND fm_score = 4)\n",
    "        THEN 'Loyal Customers'\n",
    "        WHEN (r_score = 5 AND fm_score = 2)\n",
    "          OR (r_score = 4 AND fm_score = 2)\n",
    "          OR (r_score = 3 AND fm_score = 3)\n",
    "          OR (r_score = 4 AND fm_score = 3)\n",
    "        THEN 'Potential Loyalists'\n",
    "        WHEN r_score = 5 AND fm_score = 1 \n",
    "        THEN 'Recent Customers'\n",
    "        WHEN (r_score = 4 AND fm_score = 1)\n",
    "          OR (r_score = 3 AND fm_score = 1)\n",
    "        THEN 'Promising'\n",
    "        WHEN (r_score = 3 AND fm_score = 2)\n",
    "          OR (r_score = 2 AND fm_score = 3)\n",
    "          OR (r_score = 2 AND fm_score = 2)\n",
    "        THEN 'Customers Needing Attention'\n",
    "        WHEN r_score = 2 AND fm_score = 1 \n",
    "        THEN 'About to Sleep'\n",
    "        WHEN (r_score = 2 AND fm_score = 5)\n",
    "          OR (r_score = 2 AND fm_score = 4)\n",
    "          OR (r_score = 1 AND fm_score = 3)\n",
    "        THEN 'At Risk'\n",
    "        WHEN (r_score = 1 AND fm_score = 5)\n",
    "          OR (r_score = 1 AND fm_score = 4)      \n",
    "        THEN 'Cant Lose Them'\n",
    "        WHEN r_score = 1 AND fm_score = 2 THEN 'Hibernating'\n",
    "        WHEN r_score = 1 AND fm_score = 1 THEN 'Lost'\n",
    "    END AS rfm_segment\n",
    "  FROM `mark_1.score`\n",
    "  ORDER BY CustomerID\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9 (tags/v3.7.9:13c94747c7, Aug 17 2020, 18:58:18) [MSC v.1900 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "df00bd9497c0e4715a2c3b1de05d612cc40ecd10b6fec7cf991d6657ca36bff6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
